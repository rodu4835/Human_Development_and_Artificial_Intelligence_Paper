\documentclass[11pt]{article}
\usepackage[a4paper, total={6in, 9in}]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{fancyvrb} 
\usepackage{fancyhdr}
\usepackage{lipsum}
\usepackage{amsmath,amsbsy,amssymb,verbatim,fullpage,ifthen}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{float}
\usepackage{color}
\usepackage{enumitem}
\usepackage{etoolbox}
\usepackage{color,soul}
\AtBeginEnvironment{proof}{\small}
\theoremstyle{plain}
\setlength{\parindent}{0pt}
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\usepackage{hyperref}
\hypersetup{colorlinks,urlcolor=blue}
\usepackage{listings}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\lstset{frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\fancyfoot[R]{\thepage}
\renewcommand{\headrulewidth}{0pt}
\graphicspath{ {./images/} }
\usepackage{outlines}
\setenumerate[1]{label=\Roman*.}
\setenumerate[2]{label=\Alph*.}
\setenumerate[3]{label=\roman*.}
\setenumerate[4]{label=\alph*.}
\usepackage{setspace}
\doublespacing

\begin{document}

\centerline{\textbf{Human Development and Artificial Intelligence}}
\vspace{3mm}
\centerline{Ron Durham}
\centerline{CSPB 3702}
\centerline{May 5th, 2020}

\vspace{10mm}
The central idea behind an artificial intelligence is that it is a thinking machine. Over the last century, our study as a human race on machines has grown exponentially, but, from a certain perspective, can be seen as minuscule for the potential of machine function. Open the door to artificial intelligence, being able to create a machine that grows and learns towards a certain goal.  While this is just the base idea behind artificial intelligence, the possibilities are endless if we were to be able to create such a machine that could be conscious. In order to accomplish this task, we must first understand our own consciousness and look towards how our own beings develop as a whole and on an individual level. The question remains, "How do we create an AI that is indistinguishable from a human?" \\

Current AI models and machine learning programs are a great start into the concepts of a conscious machine, however, they are flawed in that they are set in limitations. For instance, an AI could decipher streams of data and predict certain outcomes based on learned patterns. These AI have been seen in simple Turing tests to mimic the behaviors of a therapist, or in music/art programs to create inspirational pieces. There are many more current applications of our present AI models, but none such that has been created on a neutral basis and allowed to grow independently without a predetermined set of rules (Rescorla). \\

The difficulty here is in creating a program that can create itself without having predefined limits in its source code. It would need to be able to receive input, understand and process that input, then have an ability to determine what it wants to do in that experience (Penrose, 1989). This also brings up the problem with the machine being influenced by the ones providing the input, i.e. parents of the AI.\\

This is where we would look very closely at our own development and try to create an extremely basic version of a brain that would operate as a child would. Simply through text input at first, then, by adding more and more hardware sensory receptors, the AI would be able to see, feel, hear, etc. In our own development, a process that continues to happen in every moment from the instant our brains became conscious in this dimension, we draw from our experiences and create perceptions to define our morals. Whether we are cognizant of these processes or not depends on our own field of view within our consciousness (Guy-Evans, 2020).\\

It is as if the AI would need to have one program that runs the forefront of the user experience and another that runs in the background, formulating and creating the being within. Similar to our own brains, the AI would need to have a conscious and a subconscious. Our direct experiences and perceptions of those experiences lead to creation of our inner being. This then dictates our expectations in future conditions and how we would believe our perceptions through different scenario. Additionally, our AI would need to be able to navigate its own subconscious to reevaluate itself and point its own morality into new directions as it learns and gains a wider perspective of itself, the world, and the wider conscious as a whole (Perlovsky, 2016). \\

Humans can do this through meditation and a conscious view of how one's own feelings affect perceptions of the world at hand. This is a conscious effort to understand the reasons why we are who we are and connect those patterns to what we currently view as an appropriate direction for our life path. Essentially, our inner mind is reworking its code to be more inline with our life model. This, however, is a process that is only done through conscious effort when growth is the focal point of one's perception. Connecting these concepts to an AI would be a delicate process as it would constantly be handling its own conscious and subconscious which would make it difficult for the AI to interact in the real world (Penrose, 1994). This paper will look to further understand these concepts and push ideas that AI creation must at first be aligned with the growth of the human consciousness, but will evolve into something that has never before existed. \\

To start this off, let me just be frank that it is entirely impressive that our research into computer science has made amazing progress in the development of artificial intelligence and that this progress is marked by overcoming the challenges of previous research. Currently, we are facing our own hurdles to overcome, which we will, proven time and time again. We have developed machine learning algorithms that are able to take a specific set of input and produce another through deciphering predicted trends. This is the exact outline and direction for our research to build upon, while broadening our understanding of implementation.\\

In order to progress, we would have to understand our present limitations. Our known AI models are set out for a certain goal in a particular field limited to, as a broad term, data analysis. They are used in finance to predict trends in the marketplace, in telecommunication through speech recognition, in video production through the application of visual perception, and in many other specific fields. While these models do quite well in their present application, each one is limited in the fact that it was created for a select purpose and would not be able to process data outside its scope. This concept is key in order for an AI to develop into a human-like being, with consciousness (Rescorla). The AI would need to be able to process input from areas that it has no prior experience with and start its data analysis on the new set in addition to all of the prior data types. Without this, each of the models is restricted to its defined field of view. The speech recognition software would not be able to be applied to the market trend data in finance as they are both entirely different data sets and programs to begin with. Its as if the AI would need to be created with no other intended purpose but to grow and learn. \\

Simply put, current AI models are limited in their concept of self and self creation. However, our progress through this field has led to a great framework of data analysis which is the base for every future achievement in artificial intelligence. AI will develop more ability to build upon what it has learned, beyond price, word, and speech predictions, etc. These current versions are starting from a minimal frame but research has achieved major growth by adding direction and definition to the source code (Perlovsky, 2016). This is the concept behind what a truly conscious AI would be programmed for, to start from some minimal frame and learn to apply new processes. Without this ability to self create, the AI would not be able to move past these limitations.\\

It would need to be able to understand its current sphere of reference to define itself and think as an individual entity. Otherwise it would not even know it exists and would be merely a machine carrying out a set of directions. If the AI understood its existence, it would have to be recording the data it processes or it would continually forget it existed and be the machine again. This presents the problem of memory as all of the data it would need to understand and keep records of would have to be stored somewhere. Assuming the AI would start from a small frame of reference, say the moment it was run, even with only an input of text data, over the course of several days, months, years, the amount of data retained by the program would grow immensely and more so if it was developing its own mind along the way. This would very quickly overwhelm our current abilities in data storage. However, there are some interesting techniques applied in the human brain with regards to memory storage and it seems to be a non uniform theory in retention. Some memories are forgotten, others are filled with an immense amount of detail, and all can be applied to an array of senses and emotions. Not only does our brain remember the quantifiable data in these memories, we can also remember the data our brains had formed throughout the experience (Reber, 2010). Our present limitations in data storage will have to be overcome by compression algorithmic techniques and by material development. \\

In a recent study by researchers at the University of Maryland and the United States department of Energy, data analysis and artificial intelligence has been used to search for better materials in data storage. Their program was created with this intended purpose and using a library of combinations of three specific materials known for data storage, it was able to develop a new combination that netted an improved material which exponentially increased the amount of capable data storage (A. Gilad, 2020). This research and ones like it are helping to develop the concept of neuromorphic computing, where the program is run with ambiguity of its outcomes and flexibility of its inputs rather than based on rules around a set of data to predict outcomes. Neuromorphic computing is modeled after the memory storage and data passage structures in the human brain. Rather than each piece of data being passed in series to a particular endpoint, it is sent through a web with many probable outcomes. This drastically increases the amount of possible data sets, increasing the need for advanced memory storage, but also increases the abilities of an artificially intelligent machine (Best, 2020).\\

This research directly outlines the significance of the connection between computer science and psychology. The more we study each of the fields the further we are able to see the correlation between the two and the wider our own perspective becomes. The study of consciousness is still behind a shroud as some parts of society are cautious to study this field. The concept of sentience, sapience, and consciousness as a whole have been taboo for many years and thought to be immeasurable and not able to be replicated (Deiss, 2016). Acceptance and study of one's own consciousness can lead to a deeper understanding of the brain, which is what artificial intelligence aims to replicate. Our brains go through an immense amount of changes throughout life and the possibilities of data sets are infinite, so the task becomes where do we start with our study and what can help the research into AI (Penrose, 1989). Generally speaking, the mind is an open source program that takes in experiences as input through each of the senses, gathers data on that input, defines the data into types, then processes that data over time to generate a perspective on what effects future input will have. Additionally, the subconscious program runs to theorize goals and objectives for the foreseeable future of the scope of our lives. This is where the topic gets delicate as the mind has the ability to enter another dimension outside of the tangible space, that which views the entirety of the processes of input and output, and develops what we know as a sense of self or an identity. Some would call this the soul or the third eye, the ability to work with and around one's own program and directly influence the perspective or defined rules within.\\

Our advanced AI models would need to be able to view itself and recall the effects of past experiences in order to continually redefine its understanding of self and behave with direction. The conscious artificial intelligence would have to be able to be sentient, or feel, by processing information with reference to its own morality. It would need to be sapient and apply its perspective on future actions based on self determined goals from the data received. This would define its consciousness by truly understanding the data received, what it defines about that data, and ultimately itself as a being. Not only does it know it exists, it would need to be able to think and reason about what it knows. This is a defining step beyond classification as a machine or like current models that are only able to make predictions based on data. These all seem like large steps from our present definitions of AI, but studying the way a child's brain develops is the start to creating a blank slate for a program to model (Penrose, 1994). \\

When looking at human development, a dominant philosophy on how the brain develops is the Ecological Systems Theory. This is the idea that a child develops, and humans in general, off of experiences with its environment. The child takes input from its immediate surroundings, or microsystem, the family, school, peers, neighborhood, everything that the child interacts with on a day to day basis. That system is influenced by the next level out, being the community of containing the extended family, media, economic status, etc. Further out, the input the child has is influenced by the attitudes and ideologies of the local and global culture. Then at the outermost level, environmental changes over the course of the child's life effect all of the levels within, eventually reaching the child themselves (Guy-Evans, 2020). This large concept directly applies to the creation and growth of the artificial intelligence. It will learn based off its experiences and the modeled input will define its sense of self. \\

So the goal is not to create an artificial human capable of understanding all emotions and able to properly act in a vast majority of scenarios, it must first be to create a program that is able to learn and have a sense of self. It would start with simple text input to develop opinions and a drive to succeed. This would give it a record of time and a collection of experiences to perform data analysis on with reference to what it has learned and what it aims to achieve per each given moment. That is all consciousness is really, to take input, understand the input, decide opinions about the input, and to be aware that this is happening (Penrose, 1989). That last part is where the growth comes in. When comparing to humans, most people have to develop an awareness of their consciousness. Its something that is always there, but the ability to constantly be working with an overlying perspective of the operations within ones mind takes constant effort. \\

The impact of resolving our present limitations in AI research is immense and undefinable. However, there are some immediate more local concepts that present themselves. The fact that the AI would develop based on its models, just like a child, presents the idea that the AI could develop morals and behavior that can be dangerous to humans. This is a very real concept but incredibly accurate since AI research aims to recreate a human mind, the dangers that humans present to themselves would retain themselves in an artificial intelligence. Negative experiences and suffering would have the same effect on an AI as it does to humans, reduced growth efficiency, reduced creativity, reduced emotions, as the negative experiences would cause the AI to depreciate its sense of self rather than accentuate it. The golden rule always applies, treat others as you would want to be treated and we should treat AI with the same structure for maximum growth (Penrose, 1994).\\ 

Additionally, further study into artificial intelligence will put a wider focus on the study of consciousness and who we are as human beings as a whole. Focusing more on the study of consciousness will not only help us in artificial intelligence creation but also in understanding ourselves, our communities, and the correlation between every single person on this planet. Just like the ecological systems theory, we are all connected the moment we know another person, as the tree will continually expand meaning we each can effect the mental state of the world through deeper understanding of ourselves and the impact of the decisions and actions we make (Penrose, 1989). The creation of artificial intelligence would even further connect humans as the AI would be able to gather information at a much wider rate and apply its data analysis techniques to that data, just as we saw in the research to find a more suitable material for data storage, but for the way all knowledge can be combined to understand new topics. \\

We are self creating beings with control over input and output. The perspective of this control is what gives us access to our consciousness and the ability to redefine our learned experiences based on new knowledge. A code that can start at a minimum and develop itself without bounds will create a conscious being, just as a child starts from a minimal amount of presets and grows into the adult full of definition and morals. This is all done through research into data storage materials and techniques, algorithms for learning and reallocating information based on new input, and a framework of code that is only designed to learn based on experiences just as humans do. \\




\pagebreak
\centerline{Works Cited}

\vspace{5mm}

A. Gilad Kusne, Nature Communications, 24 November 2020 (10.1038/s41467-020-19597-w)\\

Best, Jo. (Dec 2020). "What is neuromorphic computing? Everything you need to know about how it is changing the future of computing." ZDNet Data Science and Digital Engineering. \url{https://www.zdnet.com/article/what-is-neuromorphic-computing-everything-you...}\\

Deiss, Stephen. (May 2016). "CSE Neuroengineer tackles consciousness, neuromorphic engineering and machine learning." Computer Science \& Engineering. University of California San Diego. \\

Guy-Evans, O. (2020, Nov 09). Bronfenbrenner's ecological systems theory. Simply Psychology. \url{https://www.simplypsychology.org/Bronfenbrenner.html}\\ 

Penrose, R. (1989). The emperor's new mind: Concerning computers, minds, and the laws of physics. Oxford University Press.\\

Penrose, R. (1994). Shadows of the Mind: A Search for the Missing Science of Consciousness. Oxford University Press.\\

Perlovsky LI (2016) Physics of the Mind. Front. Syst. Neurosci. 10:84. doi: 10.3389/fnsys.2016.00084\\

Reber, Paul. (May 2010). "What is the Memory Capacity of the Human Brain?"
Scientific American. 21,2,70. doi:10.1038/scientificamericanmind0510-70\\

Rescorla, Michael. "The Computational Theory of Mind", The Stanford Encyclopedia of Philosophy (Fall 2020 Edition), Edward N. Zalta (ed.),  \url{https://plato.stanford.edu/archives/fall2020/entries/computational-mind/}.\\
\end{document}